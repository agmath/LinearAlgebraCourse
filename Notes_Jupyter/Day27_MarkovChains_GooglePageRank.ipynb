{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+3DA+RbTIeOpqRZc7BaCF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yUpSQ0rCUtJJ","executionInfo":{"status":"ok","timestamp":1750540184408,"user_tz":240,"elapsed":8,"user":{"displayName":"Adam Gilbert","userId":"02074648007699947871"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["## Day 27: Markov Chains and the Google Page Rank Algorithm\n","\n","...A basic introduction to what we'll be doing here..."],"metadata":{"id":"KsdGD5UHalQE"}},{"cell_type":"markdown","source":["### Markov Chains\n","\n","Markov Chains result from a special class of discrete dynamical system. In particular, they are a system in which the total population does not change. For example, we may be interested in modeling the number of bicycles at each pick-up/drop-off location for a bike share system within a city. In such a scenario it is reasonable to assume that the number of bicycles remains constant from one day to the next, but their locations will change.\n","\n","> **Definition (Probability Vector):** A vector with non-negative entries, summing to $1$ can be interpreted as a *probability vector*. Each entry describes the probability (or proportion) of elements belonging to the corresponding state.\n",">\n","> **Definition (Stochastic Matrix):** A matrix whose columns are probability vectors can be called a *stochastic matrix*.\n","\n","Stochastic matrices describe how elements of a population transition between states. Because each column in the stochastic matrix sums to $1$, the population modeled by the system does not grow or decay.\n","\n","> **Definition (Markov Chain):** If $A$ is a stochastic matrix and $\\vec{x_0}$ is a probability vector, then the sequence $\\left\\{\\vec{x_k}\\right\\}$ resulting from the relationship $\\vec{x_{k+1}} = A\\vec{x_k}$ is called a *Markov Chain*."],"metadata":{"id":"lIFRug7PU1uC"}},{"cell_type":"markdown","source":["**Application 1:** Suppose you live in a country with three political parties $P$ , $Q$, and $R$. We use $P_k$, $Q_k$, and $R_k$ to denote the percentage of voters voting for that party in election $k$.\n","\n","Voters will change parties from one election to the next. Historically, it has been the case that 60% of voters stay with the same party. However, 40% of those who vote for party $P$ will vote for party $Q$ in the next election, 20% of those who vote for party $R$ will vote for party $P$ in the next election, 20% of those who vote $Q$ will vote $R$ in the next election, and 40% of those who vote $R$ will vote $Q$ in the next election. No voters will switch from party $Q$ to party $P$ or from party $P$ to party $R$.\n","\n","1. Write the state transition matrix $A$ and verify that it is a stochastic matrix.\n","2. Write expressions for $P_{k+1}$, $Q_{k+1}$, and $R_{k+1}$ in terms of $P_k$, $Q_k$, $R_k$, and the stochastic transition matrix $A$.\n","3. Suppose that initially 40% of citizens vote for party $P$, 30% vote for party $Q$, and 30% vote for party $R$. Form the vector $\\vec{x_0}$ and explain why $\\vec{x_0}$ is a probability vector.\n","4. Find $\\vec{x_1}$, the percentages who vote for the three parties in the next election. Verify that $\\vec{x_1}$ is also a probability vector and explain why $\\vec{x_k}$ will be a probability vector for every $k$.\n","5. Find the eigenvalues of the matrix $A$ and explain why the eigenspace $E_{\\lambda = 1}$ is a one-dimensional subspace of $\\mathbb{R}^3$. Then verify that $\\left\\{\\begin{bmatrix} 1\\\\ 2\\\\ 2\\end{bmatrix}\\right\\}$ is a basis vector for $E_{\\lambda = 1}$.\n","6. As every vector in $E_{\\lambda = 1}$ is a scalar multiple of $\\vec{v} = \\begin{bmatrix} 1\\\\ 2\\\\ 2\\end{bmatrix}$, find a probability vector in $E_{\\lambda = 1}$ and explain why it is the only probability vector in $E_{\\lambda = 1}$.\n","7. Describe what happens to $\\vec{x_k}$ after a very long time."],"metadata":{"id":"lWgGIrvjXNeE"}},{"cell_type":"code","source":[],"metadata":{"id":"XbiXrPLWU1L8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> **Definition (Steady State / Stationary):** As you saw in the last notebook, the vector $\\vec{x^*}$ is said to be a steady state (or fixed point) if $A\\vec{x^*} = \\vec{x^*}$. When working with Markov Chains, it is also common to call $\\vec{x^*}$ *stationary* or a *stationary vector*.\n","\n","> **Definition (Positive Matrix):** A matrix $A$ is said to be *positive* if $A$ or some power $A^k$ has only positive entries. For example, $A = \\begin{bmatrix} 1 & 1\\\\ 2 & 5\\end{bmatrix}$ is positive, $B = \\begin{bmatrix} 0 & 0.5\\\\ 1 & 0.5\\end{bmatrix}$ is positive since $B^2$ contains only positive entries, and $C = \\begin{bmatrix} 0 & 1\\\\ 1 & 0\\end{bmatrix}$ is not positive since no power $C^k$ contains only positive entries.\n","\n","> **Theorem (Perron-Frobenius):** It is possibe to show that if the matrix $A$ is a positive, stochastic matrix, then $A$'s eigenvalues satisfy $\\lambda_1 = 1$ and $\\left|\\lambda_j\\right| < 1$ for all other eigenvalues. This means that $A$ has a unique, positive steady state vector $\\vec{q}$, and every Markov Chain defined by $A$, regardless of initial state $\\vec{x_0}$, will converge to $\\vec{q}$."],"metadata":{"id":"OMGrtuh7aZ3x"}},{"cell_type":"markdown","source":["**Example:** Verify that the matrix $B = \\begin{bmatrix} 0 & 0.5\\\\ 1 & 0.5\\end{bmatrix}$ is a positive, stochastic matrix. Show that the matrix $B$ then satisfies the *Perron-Frobenius Theorem*."],"metadata":{"id":"TCS8OsPuiLKK"}},{"cell_type":"code","source":[],"metadata":{"id":"USlKxGFVaixx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Google Page Rank Algorithm\n","\n","When you use Google to run a search for a group of keywords, the search engine returns prioritized results. How does Google know which pages should rank higher than others? Certainly no humans have looked at, and ranked, the millions of webpages that exist today. Google's strategy is quite simple! The basic idea is that a web-page is of high quality if many other pages link to that page -- in particular, if many high quality webpages point to a particular page, then that page must be a very high quality page. That's it! Google's web search runs by treating the internet like a graph where each webpage is a node and the edges in the graph are hyperlinks to and from those pages.\n","\n","Markov Chains and the Perron-Frobenius Theorem give us all the tools we'll need to understand the page rank algorithm."],"metadata":{"id":"QueKwCR_asN3"}},{"cell_type":"markdown","source":["#### How Page Rank Works\n","\n","We'll need a bit more insight before we can see why Markov Chains are relevant to the Google Page Rank algorithm, so here's a bit more insight into how it works. Consider the webpage \"$j$\" whose page rank is given by a number $x_j$. The page rank is determined as follows:\n","\n","1. Each webpage divides its page rank into equal pieces, one for each outgoing hyperlink.\n","2. Each webpage gives one portion of its page rank to each page that it links out to.\n","2. For any given page, that page's rank score is the sum of the portions of page rank it receives from the pages linking to it.\n","\n","We'll examine this through a very small example!\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?export=view&id=1RDFrIqL_72l4gaZCBP-H-CPHoUZ5uPDW\" width=\"150\">\n","</center>\n"],"metadata":{"id":"jFgR_448ndwq"}},{"cell_type":"markdown","source":["**Example:** Given the teeny-tiny \"internet\" in the graph above, initialize each page with its score $x_1$, $x_2$, and $x_3$.\n","\n","1. Run throught the three-step page rank algorithm to obtain equations for the page ranks.\n","2. Use the page rank vector $\\vec{x} = \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\end{bmatrix}$ and build the matrix $G$ such that $G\\vec{x} = \\vec{x}$ (we'll call $G$ the *Google Matrix*).\n","3. Explain why $G$ is a stochastic matrix.\n","4. Since $\\vec{x}$ is defined by the equation $G\\vec{x} = \\vec{x}$, any vector in the eigenspace $E_{\\lambda = 1}$ satisfies this equation. We want to work with a single, specific vector though, so define $\\vec{x}$ to be the steady state vector and find it.\n","5. The page rank vector $\\vec{x}$ is composed of the page ranks for each of the three pages in our small example. Which of the three pages is assigned the highest rank? Discuss why it is reasonable that this page is assigned such importance.\n","6. If we begin with the initial page rank vector $\\vec{x_0} = \\begin{bmatrix} 1\\\\ 0\\\\ 0\\end{bmatrix}$, describe what the Perron-Frobenius Theorem guarantees about the long-term behavior of the Markov Chain defined by $\\vec{x_{k+1}} = G\\vec{x_k}$.\n","7. Verify that the chain converges to the steady state page rank vector.\n"],"metadata":{"id":"kSc-TtiOutxe"}},{"cell_type":"code","source":[],"metadata":{"id":"6ogomjXRauqo","executionInfo":{"status":"ok","timestamp":1750546111148,"user_tz":240,"elapsed":40,"user":{"displayName":"Adam Gilbert","userId":"02074648007699947871"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["#### Comments on the Feasibility of Page Rank\n","\n","When finding the steady state vector we are solving the matrix equation $G\\vec{x} = \\vec{x}$. That is,\n","\n","\\begin{align} G\\vec{x} &= \\vec{x}\\\\\n","\\implies G\\vec{x} - \\vec{x} &= \\vec{0}\\\\\n","\\implies \\left(G - I\\right)\\vec{x} &= \\vec{0}\n","\\end{align}\n","\n","Notice that we are trying to find the *null space* of $G - \\lambda I$ for $\\lambda = 1$. In order to find this null space, we've seen that we can row-reduce to obtain a basis for the null space. Unfortunately, row-reducing a matrix with millions of rows and trillions of columns is not feasible (not even computationally). Matrix-vector multiplication, however, is easily done -- even at this scale. Knowing that the resulting Markov Chain will converge to the steady state (by the Perron-Frobenius Theorem) indicates that all we need to do to apporximate the steady state (and therefore page rank) is repeatedly multiply our initial state vector by the matrix $G$"],"metadata":{"id":"57kt6MQyywIV"}},{"cell_type":"markdown","source":["**Example:** Complete the *page rank* analysis for the \"internet\" modeled below. Before conducting your analysis, generate a hypothesis about the page ranks you'll find.\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?export=view&id=1_dIFhV1v718d7U64f2FyU8KkFEg6MMB8\" width=\"150\">\n","</center>\n","\n"],"metadata":{"id":"Vny91ouz4ue6"}},{"cell_type":"markdown","source":["**Example:** Complete the *page rank* analysis once more, but for the more complex (but still simple in comparison) internet below. What pages do you suspect will earn the highest page ranks?\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?export=view&id=14yfaPqvXGJ7OyecvmicMlKwPenJiXlbf\" width=\"350\">\n","</center>\n"],"metadata":{"id":"2ZKeYnY-3w9n"}},{"cell_type":"code","source":[],"metadata":{"id":"gr1IcRd035oT","executionInfo":{"status":"ok","timestamp":1750549376180,"user_tz":240,"elapsed":3,"user":{"displayName":"Adam Gilbert","userId":"02074648007699947871"}}},"execution_count":1,"outputs":[]}]}