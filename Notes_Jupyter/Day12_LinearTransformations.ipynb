{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAs1RP6aTOda9Wp1LgY/85"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mr3g691ZbMOU","executionInfo":{"status":"ok","timestamp":1749216498604,"user_tz":240,"elapsed":7934,"user":{"displayName":"Adam Gilbert","userId":"02074648007699947871"}}},"outputs":[],"source":["import numpy as np\n","import sympy as sp\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["### Warm-Up Problems\n","\n","Complete the following problems as you wait for class to begin.\n","\n","1. Consider the matrix $A = \\begin{bmatrix} -2 & 0 & 5\\\\ 1 & 1 & 3\\end{bmatrix}$ and the vector $\\vec{x} = \\begin{bmatrix} 5\\\\ -4\\\\ 1\\end{bmatrix}$. Compute the product $A\\vec{x}$.\n","\n","2. Consider the matrix $A = \\begin{bmatrix} -1 & 0 & 1\\\\ 5 & 1 & -1\\\\ 0 & 0 & 3\\end{bmatrix}$ and the vector $\\vec{b} = \\begin{bmatrix} 1\\\\ 4\\\\ -2\\end{bmatrix}$. Determine whether solutions to the matrix equation $A\\vec{x} = \\vec{b}$ exists. Describe the geometry of the solution space.\n","\n","3. Let $f: \\mathbb{R}^3\\to \\mathbb{R}^2$ be defined by $f\\left(\\vec{x}\\right) = \\begin{bmatrix} -2 & 0 & 5\\\\ 1 & 1 & 3\\end{bmatrix}\\vec{x}$. Evaluate $f\\left(\\begin{bmatrix} 5\\\\ -4\\\\ 1\\end{bmatrix}\\right)$\n","\n","4. Given the same function $f$ defined in part (3), compute both $f\\left(\\begin{bmatrix} -1\\\\ 2\\\\ 2\\end{bmatrix}\\right)$ and $f\\left(-3\\cdot\\begin{bmatrix} -1\\\\ 2\\\\ 2\\end{bmatrix}\\right)$. What, if anything, do you notice?\n","\n","5. Using the same function $f$ defined in part (3) again, compute $f\\left(\\begin{bmatrix} 5\\\\ -4\\\\ 1\\end{bmatrix} + \\left(-3\\right)\\begin{bmatrix} -1\\\\ 2\\\\ 2\\end{bmatrix}\\right)$. What, if anything, do you notice now?"],"metadata":{"id":"Cb7JiaI3bUgF"}},{"cell_type":"markdown","source":["## Day 12: Linear Transformations and their Matrix Representations\n","\n","In the warmup problems above (specifically 3 - 5), you considered a function defined by matrix multiplication. In fact, this isn't the first time we've considered such functions. Each time we've encountered *matrix equations*, we've brought up this notion.\n","\n","In this notebook we'll explicitly explore functions defined via matrix vector multiplication. Rather than using the generic $f$ notation, we'll swap to $T$ and refer to functions of the form $T\\left(\\vec{x}\\right) = A\\vec{x}$ as *matrix transformations* and then argue that it is also appropriate to call them *linear transformations*."],"metadata":{"id":"PRl2PjThfUAR"}},{"cell_type":"markdown","source":["### Matrix Transformations\n","\n","Consider an $m\\times n$ matrix $A$. Recalling that matrix multiplication requires compatible dimensions, for the product $A\\vec{x}$ to be defined, the vector $\\vec{x}$ must be an $n\\times 1$ matrix, and the resulting vector $A\\vec{x}$ will be an $m\\times 1$ matrix.\n","\n","Given an $m\\times n$ matrix $A$ then, we can define a transformation $T:\\mathbb{R}^n\\to \\mathbb{R}^m$ by $T\\left(\\vec{x}\\right) = A\\vec{x}$. Such a transformation will send vectors from $\\mathbb{R}^n$ to $\\mathbb{R}^m$.\n","\n","> **Example:** Consider the transformation $T\\left(\\vec{x}\\right) = A\\vec{x}$, where the matrix $A = \\begin{bmatrix} 2 & -3\\\\ 1 & 0\\\\ -4 & 5\\end{bmatrix}$. Since the matrix $A$ is a $3\\times 2$ matrix, the transformation $T$ takes vectors from $\\mathbb{R}^2$ (its domain) to $\\mathbb{R}^3$ (its codomain). We can come up with a vector notation for the transformation as well.\n",">\n","> \\begin{align} T\\left(\\begin{bmatrix} x_1\\\\ x_2\\end{bmatrix}\\right) &= \\begin{bmatrix} 2 & -3\\\\ 1 & 0\\\\ -4 & 5\\end{bmatrix}\\begin{bmatrix} x_1\\\\ x_2\\end{bmatrix}\\\\\n","&= \\begin{bmatrix} 2x_1 - 3x_2\\\\ x_1\\\\ -4x_1 + 5x_2\\end{bmatrix}\n","\\end{align}\n",">\n","> That is, given an input vector $\\vec{x} = \\begin{bmatrix} x_1\\\\ x_2\\end{bmatrix}$, we have $T\\left(\\begin{bmatrix} x_1\\\\ x_2\\end{bmatrix}\\right) = \\begin{bmatrix} 3x_1 - 3x_2\\\\ x_1\\\\ -4x_1 + 5x_2\\end{bmatrix}$."],"metadata":{"id":"dli5pcFukf_2"}},{"cell_type":"markdown","source":["#### Writing Linear Transformations as Matrix Transformations\n","\n","In the section above, we explicitly explored matrix transformations. That is, transformations which are of the form $T\\left(\\vec{x}\\right) = A\\vec{x}$ for some $m\\times n$ matrix $A$. We saw that such transformations take vectors from $\\mathbb{R}^n$ and send them to $\\mathbb{R}^m$. Perhaps it is possible to define a more general class of *linear transformations* sending vectors from $\\mathbb{R}^n$ to $\\mathbb{R}^m$. Consider the following form:\n","\n","$$T\\left(\\begin{bmatrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n\\end{bmatrix}\\right) = \\begin{bmatrix} f_1\\left(x_1, x_2, \\cdots, x_n\\right)\\\\\n","f_2\\left(x_1, x_2, \\cdots, x_n\\right)\\\\\n","\\vdots\\\\\n","f_m\\left(x_1, x_2, \\cdots, x_n\\right)\\end{bmatrix}$$\n","\n","where each of the functions $f_i$ are linear functions, scaling and summing the entries of the input vector $\\vec{x}$. It can be shown that, for any such linear transformation, there is a corresponding matrix representation. That is, there is some matrix $A$ for which $T\\left(\\vec{x}\\right) = A\\vec{x}$.\n","\n","We won't work in total generality here. Instead, we'll use an example and show a strategy that would allow any general linear transformation to be rewritten as a corresponding matrix transformation. That is, the strategy below shows that every linear transformation corresponds to a matrix transformation.\n","\n","> **Example:** Consider the linear transformation $T\\left(\\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\\\ x_4\\end{bmatrix}\\right) = \\begin{bmatrix} x_1 - 3x_3 + x_4\\\\ x_3 - 3x_4\\end{bmatrix}$. Notice the following:\n",">\n","> \\begin{align} T\\left(\\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\\\ x_4\\end{bmatrix}\\right) &= \\begin{bmatrix} x_1 - 3x_3 + x_4\\\\ x_3 - 3x_4\\end{bmatrix}\\\\\n","&= \\begin{bmatrix} x_1\\\\ 0\\end{bmatrix} + \\begin{bmatrix} -3x_3\\\\ x_3\\end{bmatrix} + x_4\\begin{bmatrix} x_4\\\\ -3x_4\\end{bmatrix}\\\\\n","&= x_1\\begin{bmatrix}1\\\\ 0\\end{bmatrix} + x_2\\begin{bmatrix} 0\\\\ 0\\end{bmatrix} + x_3\\begin{bmatrix} -3\\\\ 1\\end{bmatrix} + x_4\\begin{bmatrix} 1\\\\ -3\\end{bmatrix}\\\\\n","&= \\begin{bmatrix}1 & 0 & -3 & 1\\\\ 0 & 0 & 1 & -3\\end{bmatrix}\\begin{bmatrix}x_1\\\\ x_2\\\\ x_3\\\\ x_4\\end{bmatrix}\n","\\end{align}\n",">\n","> That is, $T\\left(\\vec{x}\\right) = A\\vec{x}$ where $A = \\begin{bmatrix} 1 & 0 & -3 & 1\\\\ 0 & 0 & 1 & -3\\end{bmatrix}$."],"metadata":{"id":"_ltYf3d4o3oa"}},{"cell_type":"markdown","source":["#### Examples to Complete\n","\n","Before we move forward, here are a couple of example problems for you to verify your understanding with. For each example, consider the transformation $T\\left(\\vec{x}\\right) = A\\vec{x}$ where $A = \\begin{bmatrix} 2 & 1\\\\ 1 & 2\\end{bmatrix}$.\n","\n","1. Evaluate $T\\left(\\begin{bmatrix} 1\\\\ -2\\end{bmatrix}\\right)$\n","2. Evaluate $T\\left(\\begin{bmatrix} 1\\\\ 0\\end{bmatrix}\\right)$\n","3. Evaluate $T\\left(\\begin{bmatrix} 0\\\\ 1\\end{bmatrix}\\right)$\n","4. Is there a vector $\\vec{x}$ such that $T\\left(\\vec{x}\\right) = \\begin{bmatrix} 3\\\\ 0\\end{bmatrix}$\n","1. Write $T\\left(\\begin{bmatrix} x_1\\\\ x_2\\end{bmatrix}\\right)$ as a vector with two components"],"metadata":{"id":"v8-LZrdht5mt"}},{"cell_type":"markdown","source":["### Properties of Linear Transformations\n","\n","Now that we've identified that any *linear transformation* corresponds to some *matrix transformation*, we can investigate properties of *linear transformations*. All of the properties below result from properties of matrix multiplication.\n","\n","**Property 1 (Transformation of $\\vec{0}$):** $T\\left(\\vec{0}\\right) = \\vec{0}$\n","\\begin{align} \\textit{Proof. } T\\left(\\vec{0}\\right) & = A\\vec{0}\\\\\n","&= \\vec{0}\n","\\end{align}\n","**Property 2 (Linearity):** Consider the vectors $\\vec{x_1}$ and $\\vec{x_2}$, along with the scalar $c$, then $T\\left(\\vec{x_1} + c\\vec{x_2}\\right) = T\\left(\\vec{x_1}\\right) + cT\\left(\\vec{x_2}\\right)$\n","\\begin{align} \\textit{Proof. } T\\left(\\vec{x_1} + c\\vec{x_2}\\right) &= A\\left(\\vec{x_1} + c\\vec{x_2}\\right)\\\\\n","&= A\\vec{x_1} + A\\left(c\\vec{x_2}\\right)\\\\\n","&= A\\vec{x_1} + cA\\vec{x_2}\\\\\n","&= T\\left(\\vec{x_1}\\right) + cT\\left(\\vec{x_2}\\right)\n","\\end{align}\n","\n","Consider the following special vectors, which we'll investigate in greater detail soon.\n","\n","$$\\vec{e_1} = \\begin{bmatrix}1\\\\ 0\\\\ 0\\\\ \\vdots\\\\ 0\\\\ 0\\end{bmatrix}~,\\vec{e_2} = \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ \\vdots\\\\ 0\\\\ 0\\end{bmatrix},~\\cdots,~\\vec{e_n} = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ \\vdots\\\\ 0\\\\ 1\\end{bmatrix}$$\n","\n","The vectors $\\vec{e_i}$ point in the directions of the usual axes in $\\mathbb{R}^n$. For clarity, consider $\\vec{e_1} = \\begin{bmatrix} 1\\\\ 0\\end{bmatrix}$ and $\\vec{e_2} = \\begin{bmatrix} 0\\\\ 1\\end{bmatrix}$ in $\\mathbb{R}^2$.\n","\n","**Property 3 (Structure of the Matrix A):** If $A = \\begin{bmatrix} \\vec{v_1} & \\vec{v_2} & \\cdots & \\vec{v_n}\\end{bmatrix}$, then $T\\left(\\vec{e_i}\\right) = \\vec{v_i}$. This means that, if $T\\left(\\vec{x}\\right) = A\\vec{x}$, then\n","$$A = \\begin{bmatrix} T\\left(\\vec{e_1}\\right) & T\\left(\\vec{e_2}\\right) & \\cdots & T\\left(\\vec{e_n}\\right)\\end{bmatrix}$$"],"metadata":{"id":"elLMLWz0u1ZK"}},{"cell_type":"markdown","source":["This third property is particularly useful because it means that if we know $T\\left(\\vec{e_i}\\right)$ for all of those \"axis vectors\", then we can evaluate $T\\left(\\vec{x}\\right)$ for any $\\vec{x}$ in the domain of the transformation.\n","\n","> **Example:** Consider the transformation $T:\\mathbb{R}^3\\to \\mathbb{R}^4$ satisfying the following:\n",">\n",">$$T\\left(\\begin{bmatrix} 1\\\\ 0\\\\ 0\\end{bmatrix}\\right) = \\begin{bmatrix}2\\\\ -3\\\\ 1\\\\ 1\\end{bmatrix}~~~~~T\\left(\\begin{bmatrix} 0\\\\ 1\\\\ 0\\end{bmatrix}\\right) = \\begin{bmatrix} 1\\\\ 0\\\\ -2\\\\ 5\\end{bmatrix}~~~~~T\\left(\\begin{bmatrix} 0\\\\ 0\\\\ 1\\end{bmatrix}\\right) = \\begin{bmatrix} 0\\\\ 1\\\\ 4\\\\ -1\\end{bmatrix}$$\n",">\n","> Evaluate $T\\left(\\begin{bmatrix} -4\\\\ 2\\\\ -3\\end{bmatrix}\\right)$.\n",">\n",">> *Solution.* Notice the following:\n",">> \\begin{align} T\\left(\\begin{bmatrix} -4\\\\ 2\\\\ -3\\end{bmatrix}\\right) &= T\\left(-4\\begin{bmatrix} 1\\\\ 0\\\\ 0\\end{bmatrix} + 2\\begin{bmatrix} 0\\\\ 1\\\\ 0\\end{bmatrix} -3\\begin{bmatrix} 0\\\\ 0\\\\ 1\\end{bmatrix}\\right)\\\\\n","&= T\\left(-4\\begin{bmatrix}1\\\\ 0\\\\ 0\\end{bmatrix}\\right) + T\\left(2\\begin{bmatrix} 0\\\\ 1\\\\ 0\\end{bmatrix}\\right) + T\\left(-3\\begin{bmatrix} 0\\\\ 0\\\\ 1\\end{bmatrix}\\right)\\\\\n","&= -4T\\left(\\begin{bmatrix}1\\\\ 0\\\\ 0\\end{bmatrix}\\right) + 2T\\left(\\begin{bmatrix} 0\\\\ 1\\\\ 0\\end{bmatrix}\\right) + \\left(-3\\right)T\\left(\\begin{bmatrix} 0\\\\ 0\\\\ 1\\end{bmatrix}\\right)\\\\\n","&= -4\\begin{bmatrix} 2\\\\ -3\\\\ 1\\\\ 1\\end{bmatrix} + 2\\begin{bmatrix} 1\\\\ 0\\\\ -2\\\\ 5\\end{bmatrix} + \\left(-3\\right)\\begin{bmatrix} 0\\\\ 1\\\\ 4\\\\ -1\\end{bmatrix}\\\\\n","&= \\begin{bmatrix} -8\\\\ 12\\\\ -4\\\\ -4\\end{bmatrix} + \\begin{bmatrix} 2\\\\ 0\\\\ -4\\\\ 10\\end{bmatrix} + \\begin{bmatrix} 0\\\\ -3\\\\ -12\\\\ 3\\end{bmatrix}\\\\\n","&= \\begin{bmatrix} -6\\\\ 9\\\\ -20\\\\ 9\\end{bmatrix}\n","\\end{align}"],"metadata":{"id":"qlbcg-eB2Wz4"}},{"cell_type":"markdown","source":["In that recent example, we made use of an extension of the linearity property of linear transformations. We'll state it explicitly below.\n","\n","**Linear Transformations and Linear Combinations:** For any linear transformation $T$, we have that\n","\n","$$T\\left(c_1\\vec{v_1} + c_2\\vec{v_2} + \\cdots + c_n\\vec{v_n}\\right) = c_1T\\left(\\vec{v_1}\\right) + c_2T\\left(\\vec{v_2}\\right) + \\cdots + c_nT\\left(\\vec{v_n}\\right)$$\n","\n","The observation above gives rise to the **superposition principle** from engineering and physics. If we consider $\\vec{v_1},~\\vec{v_2},~\\cdots,~\\vec{v_n}$ as signals entering a system and $T\\left(\\vec{v_1}\\right),~T\\left(\\vec{v_2}\\right),~\\cdots,~T\\left(\\vec{v_n}\\right)$ as the responses of the system to each signal, then the response to a linear combination of the signals will be a linear combination of the responses to the individual signals with the same weights."],"metadata":{"id":"q6q0-g7e6eg0"}},{"cell_type":"markdown","source":["### Optional Addition: Compositions of Matrix Transformations and Discrete Dynamical Systems\n","\n","Consider whether to include the last two subsections here... I feel like this notebook has a lot in it already."],"metadata":{"id":"1Yq4pnEULXvg"}},{"cell_type":"code","source":[],"metadata":{"id":"D578puuhLmQR"},"execution_count":null,"outputs":[]}]}